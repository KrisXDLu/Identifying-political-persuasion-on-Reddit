1,0.34775,0.30391040242976464,0.4162399414776884,0.4768611670020121,0.3719676549865229,1601,1205,1062,1400,171,569,356,271,150,138,474,232,82,57,94,138
2,0.281375,0.26180765688725166,0.6814814814814815,0.6585365853658537,0.48936170212765956,1990,1777,1865,1969,1,184,52,33,8,4,54,16,5,4,15,23
3,0.373375,0.37928045080190725,0.7611241217798594,0.3460425979489876,0.3219412166780588,875,559,323,550,4,325,59,39,780,726,1316,981,345,359,288,471
4,0.396375,0.41191222570532915,0.49750830564784054,0.38333921637839746,0.3500844594594595,657,321,278,339,230,599,177,198,549,523,1086,675,568,526,445,829
5,0.404875,0.37832550860719877,0.44385382059800665,0.43082835183603757,0.3725735754539762,967,575,405,609,291,668,262,284,388,392,1009,553,358,334,310,595
When iteration is low random forest classifier, AdaBoost and Neural network Classifier is more accuracy  and when iteration increases, we can clearly see the overfit from the precison and recall although the performance increses.